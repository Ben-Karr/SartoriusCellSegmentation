{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3888f353-21d8-4f7f-b18c-50f0bb7306fe",
   "metadata": {},
   "source": [
    "### This notebook is dervied from [Slawek Biels](https://www.kaggle.com/slawekbiel/positive-score-with-detectron-2-3-training) introduction to Detectron and also had some inspiration by [Ammar Alhaj Ali](https://www.kaggle.com/ammarnassanalhajali/sartorius-segmentation-detectron2-training). The goal is to add simple and flexible augmentation and to keep track of all with Weights & Biases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "29e6efa7-bc87-4160-bac2-486badfb4e55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install torch torchvision torchaudio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e0810ac-fb80-45a7-b81d-82077427b9b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install opencv-python-headless ## \"headless\" because otherwise 'sudo apt-install' is required but not possible with sagemaker studiolab permissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "833060f0-313a-4f54-be82-3f1a80ea9f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install 'git+https://github.com/facebookresearch/detectron2.git'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c6fcdbe-6088-486a-a068-5cac3e0771a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pip install wandb --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71684c9d-268f-43ba-af88-f3f73c79178c",
   "metadata": {},
   "source": [
    "### Free space of deleted models in sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "509ffa30-b4ad-4e46-a97c-df1dfda99475",
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf /home/studio-lab-user/.local/share/Trash/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81da7baa-8fbd-4d3d-88cd-d19495f5b103",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cac4ec3a-c1a0-47a2-8efe-235d4cb91d9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Logger detectron2 (DEBUG)>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import random, cv2, os\n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np\n",
    "\n",
    "import pycocotools.mask as mask_util\n",
    "\n",
    "import detectron2\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor, DefaultTrainer\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer, ColorMode\n",
    "from detectron2.data import MetadataCatalog, DatasetCatalog\n",
    "from detectron2.data import detection_utils as utils\n",
    "from detectron2.data.datasets import register_coco_instances\n",
    "from detectron2.utils.logger import setup_logger\n",
    "from detectron2.config import CfgNode\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.utils import comm\n",
    "\n",
    "import onecycle.onecycle as onecycle\n",
    "\n",
    "import wandb\n",
    "from pprint import pprint\n",
    "import copy\n",
    "import torch\n",
    "import shutil\n",
    "setup_logger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f5bfcb1-6d53-4215-939e-38df70d492ec",
   "metadata": {},
   "source": [
    "### Set environment variable for wandb to work with sagemaker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "673367eb-69cb-4782-9380-3085e29107d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['WANDB_NOTEBOOK_NAME'] = './Detectron-wandb.ipynb'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2ca901-f740-4f98-817f-1b9fa1034899",
   "metadata": {},
   "source": [
    "### Both Detectron and WandB use configs. To help keeping track of everything, use a single dict that both can dervie parameters from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8d4dadfc-e589-409b-bb78-f0e59657e675",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_run_config(project_name, \n",
    "                     project_params, \n",
    "                     sweep = False, \n",
    "                     epochs = 5, \n",
    "                     lr = 4e-4, \n",
    "                     wd = 1e-4, \n",
    "                     batch_size = 5, \n",
    "                     roi_bs = 512, \n",
    "                     mixed_precision = False, \n",
    "                     from_pretrain = False, \n",
    "                     pretrain_path = 'models/pretrain.pth', \n",
    "                     resume = False\n",
    "                    ):\n",
    "    params = project_params[project_name]\n",
    "    \n",
    "    if from_pretrain:\n",
    "        assert(Path(pretrain_path).exists()), f'Pretrained model: \"{pretrain_path}\" doesnt exist.'\n",
    "    \n",
    "    run_config = {\n",
    "        'project': dict(\n",
    "            name = project_name,\n",
    "            train_name = project_name + '_train',\n",
    "            val_name = project_name + '_val',\n",
    "            train_annotations = params['annotation_paths']['train'],\n",
    "            val_annotations = params['annotation_paths']['val'],\n",
    "            content_path = params['content_path'],\n",
    "            sweep = sweep,\n",
    "        ),\n",
    "        ## hyper dict is replaced by sweep_config if wandb sweep is used\n",
    "        'hyper': dict(\n",
    "            epochs = epochs,\n",
    "            learning_rate = lr,\n",
    "            batch_size = batch_size,\n",
    "            roi_bs = roi_bs,\n",
    "            weight_decay = wd,\n",
    "            mixed_precision = mixed_precision,\n",
    "            nesterov = False,\n",
    "            contrast = 0.3,\n",
    "            brightness = 0.3,\n",
    "            saturation = 0.3,\n",
    "            rotation = 15,\n",
    "            crop_size = False,\n",
    "            shortest_edge_size = (440, 480, 520, 560, 580, 620),\n",
    "            hor_vert_flips = (True, True),\n",
    "        ),\n",
    "        'model': dict(\n",
    "            arch = \"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\",\n",
    "            #arch = \"COCO-InstanceSegmentation/mask_rcnn_R_101_FPN_3x.yaml\",\n",
    "            #arch = \"COCO-InstanceSegmentation/mask_rcnn_X_101_32x8d_FPN_3x.yaml\",\n",
    "            classes = params['classes'],\n",
    "            from_pretrain = from_pretrain,\n",
    "            pretrain_path = pretrain_path,\n",
    "            resume = resume\n",
    "        ),\n",
    "        'sweep_config': dict(\n",
    "            method = 'random',\n",
    "            metric = {\n",
    "                'name': 'MaP IoU',\n",
    "                'goal': 'maximize',\n",
    "            },\n",
    "            parameters = {\n",
    "                'epochs': {\n",
    "                    'value': 5,\n",
    "                },\n",
    "                'batch_size':{\n",
    "                    'values': [2, 4, 8],\n",
    "                },\n",
    "                'roi_bs':{\n",
    "                    'values': [64, 128, 256, 512],\n",
    "                },\n",
    "                'learning_rate': {\n",
    "                    #'distribution': 'uniform',\n",
    "                    #'min': 3e-4, ## 5e-5\n",
    "                    #'max': 5e-4,\n",
    "                    'value': lr,\n",
    "                },\n",
    "                'weight_decay': {\n",
    "                    'distribution': 'uniform',\n",
    "                    'min': 1e-5,\n",
    "                    'max': 1e-3,\n",
    "                    #'values': [1e-3,1e-4,1e-5],\n",
    "                    #'value': 1e-4,\n",
    "                },\n",
    "                'shortest_edge_size': {\n",
    "                    #'values': [224, 440, 520, 640, 768, 800]\n",
    "                    'value': (440, 480, 520, 560, 580, 620)\n",
    "                },\n",
    "                'hor_vert_flips': {\n",
    "                    #'values': [(True, False), (False, True), (True, True), (False, False)]\n",
    "                    'value': (True, True)\n",
    "                },\n",
    "                'contrast':{\n",
    "                    #'distribution': 'uniform',\n",
    "                    #'min': 0.05,\n",
    "                    #'max': 0.5,\n",
    "                    'value': 0.3\n",
    "                },\n",
    "                'brightness':{\n",
    "                    'value': 0.3,\n",
    "                    #'distribution': 'uniform',\n",
    "                    #'min': 0.05,\n",
    "                    #'max': 0.5,\n",
    "                },\n",
    "                'saturation':{\n",
    "                    'value': False,\n",
    "                    #'distribution': 'uniform',\n",
    "                    #'min': 0.05,\n",
    "                    #'max': 0.5,\n",
    "                },\n",
    "                'rotation': {\n",
    "                    'value': 15,\n",
    "                    #'distribution': 'uniform',\n",
    "                    #'min': 5,\n",
    "                    #'max': 45,\n",
    "                },\n",
    "                'crop_size':{\n",
    "                    'value': False, #[(224, 303),(300, 406), (448, 606),]\n",
    "                },\n",
    "                'mixed_precision':{\n",
    "                    'values': [True, False],\n",
    "                },\n",
    "                'nesterov': {\n",
    "                    'values': [True, False],\n",
    "                },\n",
    "            }\n",
    "        )\n",
    "    }\n",
    "    \n",
    "    return run_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b68548e2-b8a2-437f-a9e1-e11ebf04800c",
   "metadata": {},
   "source": [
    "### Build a detectron config from parameter dict\n",
    "See the docs [detectron2.config](https://detectron2.readthedocs.io/en/latest/modules/config.html#yaml-config-references) for details and additional parameters. Add nodes for 1cycle policy and Augmentations to be used in the default setup of the Trainer and DataLoader."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0252fe63-f4f8-4441-bde9-1a036f41d486",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_train_config(run_cfg, pretrain = False, pretrain_path = None, resize_val = False, min_size_train = None, max_size_train = None):\n",
    "    cfg = get_cfg() ## Build detectron config to add to / change values\n",
    "    \n",
    "    ## Model\n",
    "    cfg.merge_from_file(model_zoo.get_config_file(run_cfg['model']['arch']))\n",
    "    if pretrain:\n",
    "        assert(Path(pretrain_path).exists()), f'Pretrained model: \"{pretrain_path}\" doesnt exist.'\n",
    "        cfg.MODEL.WEIGHTS = pretrain_path\n",
    "    else:\n",
    "        cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(run_cfg['model']['arch'])  # Let training initialize from model zoo\n",
    "        \n",
    "    cfg.MODEL.ROI_HEADS.NUM_CLASSES = run_cfg['model']['classes']\n",
    "    cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = .5\n",
    "    \n",
    "    ## Dataloaders\n",
    "    cfg.DATASETS.TRAIN = (run_cfg['project']['train_name'],)\n",
    "    cfg.DATASETS.TEST = (run_cfg['project']['val_name'],)\n",
    "    cfg.INPUT.MASK_FORMAT = 'bitmask'\n",
    "    cfg.DATALOADER.NUM_WORKERS = 0\n",
    "\n",
    "    ## Batch sizes\n",
    "    cfg.SOLVER.IMS_PER_BATCH = run_cfg['hyper']['batch_size']\n",
    "    cfg.MODEL.ROI_HEADS.BATCH_SIZE_PER_IMAGE = run_cfg['hyper']['roi_bs']\n",
    "\n",
    "    cfg.SOLVER.BASE_LR = run_cfg['hyper']['learning_rate']     \n",
    "    \n",
    "    ## Training Phase\n",
    "    iters_per_epoch = len(DatasetCatalog.get(run_cfg['project']['train_name'])) // run_cfg['hyper']['batch_size']\n",
    "    cfg.SOLVER.MAX_ITER = run_cfg['hyper']['epochs'] * iters_per_epoch\n",
    "    print(f'Total iterations: {cfg.SOLVER.MAX_ITER}')\n",
    "    cfg.SOLVER.WEIGHT_DECAY = run_cfg['hyper']['weight_decay']\n",
    "    cfg.SOLVER.NESTEROV = run_cfg['hyper']['nesterov']\n",
    "    cfg.SOLVER.STEPS = []\n",
    "    ## 1cycle policy\n",
    "    onecycle_dict = {\n",
    "        'LR_MAX': run_cfg['hyper']['learning_rate'],\n",
    "        'DIV': 25,\n",
    "        'DIV_FINAL': 1e4,\n",
    "        'PCT': 0.3,\n",
    "        'MOMS': (0.95, 0.85, 0.95)\n",
    "    }\n",
    "    cfg.ONECYCLE = CfgNode(onecycle_dict)\n",
    "        \n",
    "    ## Augmentatinos \n",
    "    hor_flip, vert_flip = run_config['hyper']['hor_vert_flips']\n",
    "    augs_dict = {\n",
    "        'hor_flip':           hor_flip,\n",
    "        'vert_flip':          vert_flip,\n",
    "        'contrast':           run_cfg['hyper']['contrast'],\n",
    "        'brightness':         run_cfg['hyper']['brightness'],\n",
    "        'saturation':         run_cfg['hyper']['saturation'],\n",
    "        'rotation':           run_cfg['hyper']['rotation'],\n",
    "        'crop_size':          run_cfg['hyper']['crop_size'],\n",
    "        'shortest_edge_size': run_cfg['hyper']['shortest_edge_size']\n",
    "    }\n",
    "    cfg.AUGS = CfgNode(augs_dict) \n",
    "\n",
    "    ## Validation Phase\n",
    "    cfg.TEST.EVAL_PERIOD = 500\n",
    "    cfg.SOLVER.CHECKPOINT_PERIOD = 500\n",
    "    ## Turn off resize for validation\n",
    "    ## Make shure trainer has seen original image size\n",
    "    if not resize_val:\n",
    "        cfg.INPUT.MIN_SIZE_TEST = 0 \n",
    "\n",
    "    ## Mixed Precision\n",
    "    if run_config['hyper']['mixed_precision']:\n",
    "        cfg.SOLVER.AMP.ENABLED = True\n",
    "        \n",
    "    return cfg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb434db-04b2-41fe-b8ff-2c327bf067ab",
   "metadata": {},
   "source": [
    "### Project Parameters\n",
    "to easily change between pre & acctual task training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "752407ad-02fa-4629-b60f-487bfa87155a",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_params = {\n",
    "    'CellSeg': {\n",
    "        'content_path': Path('SartoriusCellSeg'),\n",
    "        'annotation_paths': {'train': 'SartoriusCellSeg/annotations_train.json',\n",
    "                             'val': 'SartoriusCellSeg/annotations_val.json'\n",
    "                            },\n",
    "        'classes': 3,\n",
    "        #'eval_mult': 4,\n",
    "        \n",
    "    },\n",
    "    'LiveCell': {\n",
    "        'content_path': Path('LiveCell/png'),\n",
    "        'annotation_paths': {'train': 'LiveCell/livecell_coco_train_encoded.json',\n",
    "                             'val': 'LiveCell/livecell_coco_val_encoded.json'\n",
    "                            },\n",
    "        'classes': 8,\n",
    "        #'eval_mult': 0.25,\n",
    "        \n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2e870e6f-8e05-4253-bdea-1aa009ab2214",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'hyper': {'batch_size': 4,\n",
      "           'brightness': 0.3,\n",
      "           'contrast': 0.3,\n",
      "           'crop_size': False,\n",
      "           'epochs': 25,\n",
      "           'hor_vert_flips': (True, True),\n",
      "           'learning_rate': 0.003,\n",
      "           'mixed_precision': False,\n",
      "           'nesterov': False,\n",
      "           'roi_bs': 128,\n",
      "           'rotation': 15,\n",
      "           'saturation': 0.3,\n",
      "           'shortest_edge_size': (440, 480, 520, 560, 580, 620),\n",
      "           'weight_decay': 0.0001},\n",
      " 'model': {'arch': 'COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml',\n",
      "           'classes': 3,\n",
      "           'from_pretrain': False,\n",
      "           'pretrain_path': 'models/model_XRes_Small50eposCycle.pth',\n",
      "           'resume': False},\n",
      " 'project': {'content_path': PosixPath('SartoriusCellSeg'),\n",
      "             'name': 'CellSeg',\n",
      "             'sweep': True,\n",
      "             'train_annotations': 'SartoriusCellSeg/annotations_train.json',\n",
      "             'train_name': 'CellSeg_train',\n",
      "             'val_annotations': 'SartoriusCellSeg/annotations_val.json',\n",
      "             'val_name': 'CellSeg_val'},\n",
      " 'sweep_config': {'method': 'random',\n",
      "                  'metric': {'goal': 'maximize', 'name': 'MaP IoU'},\n",
      "                  'parameters': {'batch_size': {'values': [2, 4, 8]},\n",
      "                                 'brightness': {'value': 0.3},\n",
      "                                 'contrast': {'value': 0.3},\n",
      "                                 'crop_size': {'value': False},\n",
      "                                 'epochs': {'value': 5},\n",
      "                                 'hor_vert_flips': {'value': (True, True)},\n",
      "                                 'learning_rate': {'value': 0.003},\n",
      "                                 'mixed_precision': {'values': [True, False]},\n",
      "                                 'nesterov': {'values': [True, False]},\n",
      "                                 'roi_bs': {'values': [64, 128, 256, 512]},\n",
      "                                 'rotation': {'value': 15},\n",
      "                                 'saturation': {'value': False},\n",
      "                                 'shortest_edge_size': {'value': (440,\n",
      "                                                                  480,\n",
      "                                                                  520,\n",
      "                                                                  560,\n",
      "                                                                  580,\n",
      "                                                                  620)},\n",
      "                                 'weight_decay': {'distribution': 'uniform',\n",
      "                                                  'max': 0.001,\n",
      "                                                  'min': 1e-05}}}}\n"
     ]
    }
   ],
   "source": [
    "run_config = build_run_config('CellSeg', project_params, sweep = True, epochs = 25, from_pretrain = False, pretrain_path ='models/model_XRes_Small50eposCycle.pth' , resume = False, batch_size = 4, roi_bs = 128, lr = 3e-3)\n",
    "pprint(run_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45e4eb70-c44d-4d73-a40a-1d24afe25bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "register_coco_instances(run_config['project']['train_name'],{}, run_config['project']['train_annotations'], run_config['project']['content_path'])\n",
    "register_coco_instances(run_config['project']['val_name'],{}, run_config['project']['val_annotations'], run_config['project']['content_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ce55c4-1f31-4ee6-87ee-c0fb1ce40ecd",
   "metadata": {},
   "source": [
    "## LR Finder\n",
    "Uncomment to use the learning rate finder. Best to comment out, set learning rate in config and rerun notebook to free memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f34cc760-cb81-4d64-9967-3d347f2c1f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cfg = build_train_config(run_config, mixed_precision=True)\n",
    "#os.makedirs(cfg.OUTPUT_DIR, exist_ok = True)\n",
    "#trainer = onecycle.CycleTrainer(cfg)\n",
    "#lrs = trainer.lr_find(end_lr = 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34de6ad-17ef-4459-8dad-d6b06ea828c1",
   "metadata": {},
   "source": [
    "### Result of lr_find: \n",
    "* XRes 101 | Small | CellSeg: 1e-3\n",
    "* XRes 101 | Full | CellSeg: 5e-3\n",
    "* Resnet 50 | Full | CellSeg: 5e-3\n",
    "* Resnet 50 | Full | CellSeg | fp16: 3e-3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ca1cafe-a99b-47ee-8b5f-ae06c195dd18",
   "metadata": {},
   "source": [
    "### Perform training with previously set parameters and wandb to record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cee468b-8249-42e4-869d-3fdc57cb185e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(cfg = None):   \n",
    "    \n",
    "    with wandb.init(project = run_config['project']['name'], sync_tensorboard = True, name = 'R50-oneCycle-sweeps'):\n",
    "        \n",
    "        if run_config['project']['sweep']:\n",
    "            run_config['hyper'] = wandb.config\n",
    "\n",
    "        cfg = build_train_config(run_config, pretrain = run_config['model']['from_pretrain'], pretrain_path= run_config['model']['pretrain_path'])\n",
    "\n",
    "        if not run_config['model']['resume']:\n",
    "            ## Clear the output folder if training doesn't continue earlier training\n",
    "            if os.path.isdir(cfg.OUTPUT_DIR):\n",
    "                shutil.rmtree(cfg.OUTPUT_DIR)\n",
    "            os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "        trainer = onecycle.CycleTrainer(cfg)\n",
    "        #trainer = onecycle.AugTrainer(cfg)\n",
    "        trainer.resume_or_load(resume=run_config['model']['resume'])\n",
    "\n",
    "        trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1849a999-8d8d-4a12-a91f-e96729a32cfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: qwchocc2 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbrightness: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcontrast: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcrop_size: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thor_vert_flips: [True, True]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmixed_precision: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnesterov: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \troi_bs: 512\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trotation: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsaturation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tshortest_edge_size: [440, 480, 520, 560, 580, 620]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 8.546613308981868e-05\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mben-karr\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ben-karr/CellSeg/runs/qwchocc2\" target=\"_blank\">R50-oneCycle-sweeps</a></strong> to <a href=\"https://wandb.ai/ben-karr/CellSeg\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ben-karr/CellSeg/sweeps/gzjsnknx\" target=\"_blank\">https://wandb.ai/ben-karr/CellSeg/sweeps/gzjsnknx</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/06 15:28:20 d2.data.datasets.coco]: \u001b[0mLoading SartoriusCellSeg/annotations_train.json takes 1.31 seconds.\n",
      "\u001b[32m[01/06 15:28:20 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from SartoriusCellSeg/annotations_train.json\n",
      "Total iterations: 605\n",
      "\u001b[32m[01/06 15:28:28 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [RandomRotation(angle=[-15, 15], expand=False), ResizeShortestEdge(short_edge_length=[440, 480, 520, 560, 580, 620], max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomFlip(prob=0.5, horizontal=False, vertical=True), RandomContrast(intensity_min=0.7, intensity_max=1.3), RandomBrightness(intensity_min=0.7, intensity_max=1.3)]\n",
      "\u001b[32m[01/06 15:28:29 d2.data.datasets.coco]: \u001b[0mLoading SartoriusCellSeg/annotations_train.json takes 1.02 seconds.\n",
      "\u001b[32m[01/06 15:28:29 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from SartoriusCellSeg/annotations_train.json\n",
      "\u001b[32m[01/06 15:28:29 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[01/06 15:28:29 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 41615        |   astro    | 8122         |    cort    | 8492         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 58229        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[01/06 15:28:29 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[01/06 15:28:29 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/06 15:28:29 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/06 15:28:30 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/.conda/envs/test/lib/python3.9/site-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n",
      "  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n",
      "/home/studio-lab-user/SartoriusCellSegmentation/onecycle.py:130: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/06 15:29:16 d2.utils.events]: \u001b[0m eta: 0:19:08  iter: 19  total_loss: 2.783  loss_cls: 1.032  loss_box_reg: 0.2699  loss_mask: 0.6875  loss_rpn_cls: 0.4506  loss_rpn_loc: 0.4149  time: 2.4137  data_time: 1.8116  lr: 0.00019717  max_mem: 3815M\n",
      "\u001b[32m[01/06 15:30:01 d2.utils.events]: \u001b[0m eta: 0:17:29  iter: 39  total_loss: 2.492  loss_cls: 0.7001  loss_box_reg: 0.4326  loss_mask: 0.6315  loss_rpn_cls: 0.348  loss_rpn_loc: 0.3856  time: 2.3329  data_time: 1.7632  lr: 0.00043583  max_mem: 3869M\n",
      "\u001b[32m[01/06 15:30:50 d2.utils.events]: \u001b[0m eta: 0:20:20  iter: 59  total_loss: 2.394  loss_cls: 0.6674  loss_box_reg: 0.5779  loss_mask: 0.4984  loss_rpn_cls: 0.2685  loss_rpn_loc: 0.3399  time: 2.3643  data_time: 1.8863  lr: 0.00080787  max_mem: 4064M\n",
      "\u001b[32m[01/06 15:31:34 d2.utils.events]: \u001b[0m eta: 0:17:27  iter: 79  total_loss: 2.188  loss_cls: 0.5658  loss_box_reg: 0.6089  loss_mask: 0.4188  loss_rpn_cls: 0.2314  loss_rpn_loc: 0.3527  time: 2.3227  data_time: 1.6993  lr: 0.0012691  max_mem: 4214M\n",
      "\u001b[32m[01/06 15:32:19 d2.utils.events]: \u001b[0m eta: 0:17:01  iter: 99  total_loss: 2.081  loss_cls: 0.5579  loss_box_reg: 0.616  loss_mask: 0.3817  loss_rpn_cls: 0.2315  loss_rpn_loc: 0.3405  time: 2.3135  data_time: 1.7554  lr: 0.0017649  max_mem: 4214M\n",
      "\u001b[32m[01/06 15:33:09 d2.utils.events]: \u001b[0m eta: 0:16:26  iter: 119  total_loss: 2.091  loss_cls: 0.5094  loss_box_reg: 0.5903  loss_mask: 0.3831  loss_rpn_cls: 0.208  loss_rpn_loc: 0.3288  time: 2.3450  data_time: 1.9678  lr: 0.0022364  max_mem: 4214M\n",
      "\u001b[32m[01/06 15:33:54 d2.utils.events]: \u001b[0m eta: 0:15:40  iter: 139  total_loss: 1.853  loss_cls: 0.4459  loss_box_reg: 0.5489  loss_mask: 0.3637  loss_rpn_cls: 0.1592  loss_rpn_loc: 0.3111  time: 2.3317  data_time: 1.7256  lr: 0.0026276  max_mem: 4214M\n",
      "\u001b[32m[01/06 15:34:36 d2.utils.events]: \u001b[0m eta: 0:14:59  iter: 159  total_loss: 1.881  loss_cls: 0.4551  loss_box_reg: 0.5837  loss_mask: 0.3568  loss_rpn_cls: 0.1941  loss_rpn_loc: 0.3091  time: 2.3027  data_time: 1.5846  lr: 0.0028922  max_mem: 4214M\n",
      "\u001b[32m[01/06 15:35:20 d2.utils.events]: \u001b[0m eta: 0:14:19  iter: 179  total_loss: 1.79  loss_cls: 0.3831  loss_box_reg: 0.5665  loss_mask: 0.3547  loss_rpn_cls: 0.1752  loss_rpn_loc: 0.3175  time: 2.2912  data_time: 1.6740  lr: 0.0029987  max_mem: 4214M\n",
      "\u001b[32m[01/06 15:36:01 d2.utils.events]: \u001b[0m eta: 0:13:38  iter: 199  total_loss: 1.851  loss_cls: 0.4132  loss_box_reg: 0.5738  loss_mask: 0.3577  loss_rpn_cls: 0.167  loss_rpn_loc: 0.3033  time: 2.2642  data_time: 1.5017  lr: 0.0029874  max_mem: 4214M\n",
      "\u001b[32m[01/06 15:37:04 d2.utils.events]: \u001b[0m eta: 0:13:26  iter: 219  total_loss: 1.828  loss_cls: 0.4114  loss_box_reg: 0.5295  loss_mask: 0.3763  loss_rpn_cls: 0.1759  loss_rpn_loc: 0.3245  time: 2.3433  data_time: 2.5454  lr: 0.0029423  max_mem: 4214M\n",
      "\u001b[32m[01/06 15:37:51 d2.utils.events]: \u001b[0m eta: 0:12:53  iter: 239  total_loss: 1.813  loss_cls: 0.3938  loss_box_reg: 0.5504  loss_mask: 0.3671  loss_rpn_cls: 0.1529  loss_rpn_loc: 0.308  time: 2.3472  data_time: 1.8457  lr: 0.0028656  max_mem: 4214M\n",
      "\u001b[32m[01/06 15:38:32 d2.utils.events]: \u001b[0m eta: 0:12:06  iter: 259  total_loss: 1.712  loss_cls: 0.3489  loss_box_reg: 0.5628  loss_mask: 0.361  loss_rpn_cls: 0.1472  loss_rpn_loc: 0.3049  time: 2.3229  data_time: 1.5110  lr: 0.0027589  max_mem: 4214M\n",
      "\u001b[32m[01/06 15:39:26 d2.utils.events]: \u001b[0m eta: 0:11:27  iter: 279  total_loss: 1.834  loss_cls: 0.4125  loss_box_reg: 0.5664  loss_mask: 0.3598  loss_rpn_cls: 0.1809  loss_rpn_loc: 0.3299  time: 2.3485  data_time: 2.1123  lr: 0.0026245  max_mem: 4214M\n",
      "\u001b[32m[01/06 15:40:13 d2.utils.events]: \u001b[0m eta: 0:10:47  iter: 299  total_loss: 1.72  loss_cls: 0.3605  loss_box_reg: 0.536  loss_mask: 0.3604  loss_rpn_cls: 0.1622  loss_rpn_loc: 0.3019  time: 2.3498  data_time: 1.8076  lr: 0.0024654  max_mem: 4214M\n",
      "\u001b[32m[01/06 15:40:55 d2.utils.events]: \u001b[0m eta: 0:09:57  iter: 319  total_loss: 1.765  loss_cls: 0.3819  loss_box_reg: 0.5719  loss_mask: 0.3522  loss_rpn_cls: 0.1604  loss_rpn_loc: 0.3178  time: 2.3358  data_time: 1.6080  lr: 0.0022851  max_mem: 4214M\n",
      "\u001b[32m[01/06 15:41:45 d2.utils.events]: \u001b[0m eta: 0:09:20  iter: 339  total_loss: 1.656  loss_cls: 0.3142  loss_box_reg: 0.5319  loss_mask: 0.3525  loss_rpn_cls: 0.166  loss_rpn_loc: 0.2962  time: 2.3444  data_time: 1.9479  lr: 0.0020876  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:42:35 d2.utils.events]: \u001b[0m eta: 0:08:39  iter: 359  total_loss: 1.737  loss_cls: 0.3692  loss_box_reg: 0.547  loss_mask: 0.3527  loss_rpn_cls: 0.1691  loss_rpn_loc: 0.2869  time: 2.3520  data_time: 1.9270  lr: 0.0018771  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:43:17 d2.utils.events]: \u001b[0m eta: 0:07:55  iter: 379  total_loss: 1.705  loss_cls: 0.3723  loss_box_reg: 0.5556  loss_mask: 0.3544  loss_rpn_cls: 0.1623  loss_rpn_loc: 0.2944  time: 2.3394  data_time: 1.5830  lr: 0.0016584  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:43:59 d2.utils.events]: \u001b[0m eta: 0:07:11  iter: 399  total_loss: 1.669  loss_cls: 0.3497  loss_box_reg: 0.5382  loss_mask: 0.3458  loss_rpn_cls: 0.1616  loss_rpn_loc: 0.2863  time: 2.3282  data_time: 1.5994  lr: 0.0014362  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:44:50 d2.utils.events]: \u001b[0m eta: 0:06:31  iter: 419  total_loss: 1.668  loss_cls: 0.3362  loss_box_reg: 0.5378  loss_mask: 0.3495  loss_rpn_cls: 0.1377  loss_rpn_loc: 0.2859  time: 2.3387  data_time: 2.0035  lr: 0.0012154  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:45:36 d2.utils.events]: \u001b[0m eta: 0:05:47  iter: 439  total_loss: 1.669  loss_cls: 0.3411  loss_box_reg: 0.5363  loss_mask: 0.3528  loss_rpn_cls: 0.1312  loss_rpn_loc: 0.2829  time: 2.3370  data_time: 1.7806  lr: 0.0010008  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:46:27 d2.utils.events]: \u001b[0m eta: 0:05:06  iter: 459  total_loss: 1.743  loss_cls: 0.3632  loss_box_reg: 0.548  loss_mask: 0.3513  loss_rpn_cls: 0.1578  loss_rpn_loc: 0.3203  time: 2.3461  data_time: 2.0025  lr: 0.00079727  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:47:20 d2.utils.events]: \u001b[0m eta: 0:04:25  iter: 479  total_loss: 1.714  loss_cls: 0.3707  loss_box_reg: 0.5377  loss_mask: 0.347  loss_rpn_cls: 0.1508  loss_rpn_loc: 0.296  time: 2.3578  data_time: 2.0756  lr: 0.00060914  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:48:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from SartoriusCellSeg/annotations_val.json\n",
      "\u001b[32m[01/06 15:48:00 d2.data.build]: \u001b[0mDistribution of instances among all 3 categories:\n",
      "\u001b[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |\n",
      "|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|\n",
      "|   shsy5y   | 10671        |   astro    | 2400         |    cort    | 2285         |\n",
      "|            |              |            |              |            |              |\n",
      "|   total    | 15356        |            |              |            |              |\u001b[0m\n",
      "\u001b[32m[01/06 15:48:00 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(0, 0), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/06 15:48:00 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/06 15:48:00 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/06 15:48:00 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from SartoriusCellSeg/annotations_val.json\n",
      "\u001b[32m[01/06 15:48:00 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/06 15:48:01 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0102 s/iter. Inference: 0.0572 s/iter. Eval: 0.0153 s/iter. Total: 0.0827 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/06 15:48:07 d2.evaluation.evaluator]: \u001b[0mInference done 64/121. Dataloading: 0.0131 s/iter. Inference: 0.0596 s/iter. Eval: 0.0219 s/iter. Total: 0.0946 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/06 15:48:12 d2.evaluation.evaluator]: \u001b[0mInference done 116/121. Dataloading: 0.0145 s/iter. Inference: 0.0596 s/iter. Eval: 0.0218 s/iter. Total: 0.0960 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/06 15:48:12 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.107098 (0.095751 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/06 15:48:12 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.059584 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/06 15:48:12 d2.engine.defaults]: \u001b[0mEvaluation results for CellSeg_val in csv format:\n",
      "\u001b[32m[01/06 15:48:12 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.20350062085996998\n",
      "\u001b[32m[01/06 15:48:12 d2.engine.hooks]: \u001b[0mSaved first model at 0.20350 @ 499 steps\n",
      "\u001b[32m[01/06 15:48:12 d2.utils.events]: \u001b[0m eta: 0:03:41  iter: 499  total_loss: 1.723  loss_cls: 0.3325  loss_box_reg: 0.5605  loss_mask: 0.3513  loss_rpn_cls: 0.1407  loss_rpn_loc: 0.2855  time: 2.3417  data_time: 1.4600  lr: 0.00044058  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:49:02 d2.utils.events]: \u001b[0m eta: 0:02:59  iter: 519  total_loss: 1.662  loss_cls: 0.3321  loss_box_reg: 0.4936  loss_mask: 0.3546  loss_rpn_cls: 0.1711  loss_rpn_loc: 0.2915  time: 2.3470  data_time: 1.9347  lr: 0.0002953  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:49:47 d2.utils.events]: \u001b[0m eta: 0:02:16  iter: 539  total_loss: 1.68  loss_cls: 0.3396  loss_box_reg: 0.5387  loss_mask: 0.3421  loss_rpn_cls: 0.1443  loss_rpn_loc: 0.2811  time: 2.3438  data_time: 1.7283  lr: 0.0001765  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:50:34 d2.utils.events]: \u001b[0m eta: 0:01:35  iter: 559  total_loss: 1.707  loss_cls: 0.3257  loss_box_reg: 0.536  loss_mask: 0.3436  loss_rpn_cls: 0.1484  loss_rpn_loc: 0.2847  time: 2.3440  data_time: 1.8093  lr: 8.6779e-05  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:51:28 d2.utils.events]: \u001b[0m eta: 0:00:53  iter: 579  total_loss: 1.657  loss_cls: 0.3546  loss_box_reg: 0.5154  loss_mask: 0.3531  loss_rpn_cls: 0.1541  loss_rpn_loc: 0.276  time: 2.3568  data_time: 2.1414  lr: 2.8111e-05  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:52:14 d2.utils.events]: \u001b[0m eta: 0:00:10  iter: 599  total_loss: 1.567  loss_cls: 0.3041  loss_box_reg: 0.4924  loss_mask: 0.341  loss_rpn_cls: 0.1093  loss_rpn_loc: 0.2746  time: 2.3548  data_time: 1.7718  lr: 1.7854e-06  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:52:23 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 604  total_loss: 1.544  loss_cls: 0.3041  loss_box_reg: 0.5002  loss_mask: 0.3447  loss_rpn_cls: 0.1142  loss_rpn_loc: 0.2724  time: 2.3492  data_time: 1.6653  lr: 3.4127e-07  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:52:23 d2.engine.hooks]: \u001b[0mOverall training speed: 603 iterations in 0:23:36 (2.3492 s / it)\n",
      "\u001b[32m[01/06 15:52:23 d2.engine.hooks]: \u001b[0mTotal training time: 0:23:50 (0:00:13 on hooks)\n",
      "\u001b[32m[01/06 15:52:23 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from SartoriusCellSeg/annotations_val.json\n",
      "\u001b[32m[01/06 15:52:24 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(0, 0), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/06 15:52:24 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/06 15:52:24 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/06 15:52:24 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from SartoriusCellSeg/annotations_val.json\n",
      "\u001b[32m[01/06 15:52:24 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/06 15:52:25 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0091 s/iter. Inference: 0.0582 s/iter. Eval: 0.0167 s/iter. Total: 0.0841 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/06 15:52:30 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0117 s/iter. Inference: 0.0614 s/iter. Eval: 0.0236 s/iter. Total: 0.0968 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/06 15:52:35 d2.evaluation.evaluator]: \u001b[0mInference done 112/121. Dataloading: 0.0122 s/iter. Inference: 0.0619 s/iter. Eval: 0.0248 s/iter. Total: 0.0989 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/06 15:52:36 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.398284 (0.098261 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/06 15:52:36 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.061684 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/06 15:52:36 d2.engine.defaults]: \u001b[0mEvaluation results for CellSeg_val in csv format:\n",
      "\u001b[32m[01/06 15:52:36 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.20531985874774927\n",
      "\u001b[32m[01/06 15:52:36 d2.engine.hooks]: \u001b[0mSaved best model as latest eval score for MaP IoU is 0.20532, better than last best score 0.20350 @ iteration 499.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 106... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MaP IoU</td><td>▁█</td></tr><tr><td>data_time</td><td>▂▃▆▃▆▄▃▄▄▄█▅▂▇▆▂▅▅▃▄▆▄▆▆▁▅▃▅▆▃▃</td></tr><tr><td>eta_seconds</td><td>█▇█▇▇▇▆▆▆▆▆▅▅▅▅▄▄▄▄▃▃▃▃▃▂▂▂▂▁▁▁</td></tr><tr><td>fast_rcnn/cls_accuracy</td><td>▂▃▁▃▃▃▅▅▆▅▅▅▇▅▆▆▇▆▆▇▆▆▆▅▇▇▆▆▆██</td></tr><tr><td>fast_rcnn/false_negative</td><td>███▅▅▅▄▄▂▃▄▃▂▃▂▂▁▂▃▂▁▂▂▃▂▂▁▂▂▁▁</td></tr><tr><td>fast_rcnn/fg_cls_accuracy</td><td>▁▁▁▃▄▄▅▅▇▆▅▆▇▆▇▇█▇▆▇█▇▇▆▇▇█▇▇██</td></tr><tr><td>global_step</td><td>▁▁▁▂▂▂▂▃▃▃▃▄▄▄▄▅▅▅▅▆▆▆▆▆▇▇▇▇████</td></tr><tr><td>loss_box_reg</td><td>▁▄▇██▇▇▇▇▇▆▇▇▇▆▇▆▇▇▆▆▆▇▆▇▆▆▆▆▆▆</td></tr><tr><td>loss_cls</td><td>█▅▄▄▃▃▂▂▂▂▂▂▁▂▂▂▁▂▂▁▁▁▂▂▁▁▁▁▁▁▁</td></tr><tr><td>loss_mask</td><td>█▇▄▃▂▂▁▁▁▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>loss_rpn_cls</td><td>█▆▄▄▄▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▁▂▂▂▂▂▂▂▁▁</td></tr><tr><td>loss_rpn_loc</td><td>█▇▄▅▄▄▃▃▃▃▄▃▃▄▂▃▂▂▂▂▂▂▃▂▂▂▁▂▁▁▁</td></tr><tr><td>lr</td><td>▁▂▃▄▅▆▇█████▇▇▇▆▆▅▅▄▄▃▃▂▂▂▁▁▁▁▁</td></tr><tr><td>mask_rcnn/accuracy</td><td>▁▂▄▆▇▇▇███▇▇███████████████████</td></tr><tr><td>mask_rcnn/false_negative</td><td>▆█▅▇▅▃▄▃▂▃▃▃▂▃▂▃▂▂▁▁▂▂▂▂▂▁▂▂▂▂▁</td></tr><tr><td>mask_rcnn/false_positive</td><td>██▅▂▁▂▁▂▂▁▂▁▂▁▂▁▂▁▁▁▁▂▁▁▁▂▁▁▂▂▂</td></tr><tr><td>momentum</td><td>█▇▆▅▄▃▂▁▁▁▁▁▂▂▂▃▃▄▄▅▅▆▆▇▇▇█████</td></tr><tr><td>roi_head/num_bg_samples</td><td>█▅▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▂</td></tr><tr><td>roi_head/num_fg_samples</td><td>▁▄█▇█████████████████████████▇▇</td></tr><tr><td>rpn/num_neg_anchors</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>rpn/num_pos_anchors</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>time</td><td>▄▃▆▃▆▄▃▄▄▄█▅▂█▆▂▅▅▃▃▆▃▆▇▁▅▃▅▇▃▃</td></tr><tr><td>total_loss</td><td>█▆▆▅▄▄▃▃▂▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▂▂▂▁▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MaP IoU</td><td>0.20532</td></tr><tr><td>data_time</td><td>1.36527</td></tr><tr><td>eta_seconds</td><td>0.0</td></tr><tr><td>fast_rcnn/cls_accuracy</td><td>0.87793</td></tr><tr><td>fast_rcnn/false_negative</td><td>0.35524</td></tr><tr><td>fast_rcnn/fg_cls_accuracy</td><td>0.64476</td></tr><tr><td>global_step</td><td>605</td></tr><tr><td>loss_box_reg</td><td>0.50019</td></tr><tr><td>loss_cls</td><td>0.3041</td></tr><tr><td>loss_mask</td><td>0.34475</td></tr><tr><td>loss_rpn_cls</td><td>0.11415</td></tr><tr><td>loss_rpn_loc</td><td>0.27244</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>mask_rcnn/accuracy</td><td>0.84031</td></tr><tr><td>mask_rcnn/false_negative</td><td>0.12155</td></tr><tr><td>mask_rcnn/false_positive</td><td>0.22253</td></tr><tr><td>momentum</td><td>0.95</td></tr><tr><td>roi_head/num_bg_samples</td><td>388.5</td></tr><tr><td>roi_head/num_fg_samples</td><td>123.5</td></tr><tr><td>rpn/num_neg_anchors</td><td>128.0</td></tr><tr><td>rpn/num_pos_anchors</td><td>128.0</td></tr><tr><td>time</td><td>1.81401</td></tr><tr><td>total_loss</td><td>1.54428</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">R50-oneCycle-sweeps</strong>: <a href=\"https://wandb.ai/ben-karr/CellSeg/runs/qwchocc2\" target=\"_blank\">https://wandb.ai/ben-karr/CellSeg/runs/qwchocc2</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220106_152816-qwchocc2/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 047ylhyp with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 2\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbrightness: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcontrast: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcrop_size: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thor_vert_flips: [True, True]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmixed_precision: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnesterov: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \troi_bs: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trotation: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsaturation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tshortest_edge_size: [440, 480, 520, 560, 580, 620]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.00015841263267251242\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ben-karr/CellSeg/runs/047ylhyp\" target=\"_blank\">R50-oneCycle-sweeps</a></strong> to <a href=\"https://wandb.ai/ben-karr/CellSeg\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ben-karr/CellSeg/sweeps/gzjsnknx\" target=\"_blank\">https://wandb.ai/ben-karr/CellSeg/sweeps/gzjsnknx</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/06 15:52:52 d2.data.datasets.coco]: \u001b[0mLoading SartoriusCellSeg/annotations_train.json takes 1.10 seconds.\n",
      "\u001b[32m[01/06 15:52:52 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from SartoriusCellSeg/annotations_train.json\n",
      "Total iterations: 1210\n",
      "\u001b[32m[01/06 15:52:53 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [RandomRotation(angle=[-15, 15], expand=False), ResizeShortestEdge(short_edge_length=[440, 480, 520, 560, 580, 620], max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomFlip(prob=0.5, horizontal=False, vertical=True), RandomContrast(intensity_min=0.7, intensity_max=1.3), RandomBrightness(intensity_min=0.7, intensity_max=1.3)]\n",
      "\u001b[32m[01/06 15:52:54 d2.data.datasets.coco]: \u001b[0mLoading SartoriusCellSeg/annotations_train.json takes 1.03 seconds.\n",
      "\u001b[32m[01/06 15:52:54 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from SartoriusCellSeg/annotations_train.json\n",
      "\u001b[32m[01/06 15:52:55 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[01/06 15:52:55 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[01/06 15:52:55 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/06 15:52:55 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/06 15:52:55 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/SartoriusCellSegmentation/onecycle.py:130: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/06 15:53:17 d2.utils.events]: \u001b[0m eta: 0:19:28  iter: 19  total_loss: 3.052  loss_cls: 1.061  loss_box_reg: 0.4329  loss_mask: 0.6848  loss_rpn_cls: 0.5307  loss_rpn_loc: 0.3976  time: 1.1476  data_time: 0.8809  lr: 0.00013942  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:53:37 d2.utils.events]: \u001b[0m eta: 0:13:01  iter: 39  total_loss: 2.582  loss_cls: 0.7654  loss_box_reg: 0.5234  loss_mask: 0.6389  loss_rpn_cls: 0.3856  loss_rpn_loc: 0.3796  time: 1.0660  data_time: 0.8100  lr: 0.00020125  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:53:56 d2.utils.events]: \u001b[0m eta: 0:12:19  iter: 59  total_loss: 2.564  loss_cls: 0.7173  loss_box_reg: 0.6147  loss_mask: 0.5646  loss_rpn_cls: 0.3045  loss_rpn_loc: 0.3676  time: 1.0268  data_time: 0.7704  lr: 0.00030368  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:54:21 d2.utils.events]: \u001b[0m eta: 0:12:35  iter: 79  total_loss: 2.34  loss_cls: 0.6558  loss_box_reg: 0.6133  loss_mask: 0.4772  loss_rpn_cls: 0.2556  loss_rpn_loc: 0.3468  time: 1.0942  data_time: 1.0775  lr: 0.00044366  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:54:39 d2.utils.events]: \u001b[0m eta: 0:11:29  iter: 99  total_loss: 2.202  loss_cls: 0.6152  loss_box_reg: 0.6399  loss_mask: 0.4094  loss_rpn_cls: 0.1883  loss_rpn_loc: 0.3403  time: 1.0487  data_time: 0.6958  lr: 0.000617  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:54:55 d2.utils.events]: \u001b[0m eta: 0:11:10  iter: 119  total_loss: 2.033  loss_cls: 0.5375  loss_box_reg: 0.6201  loss_mask: 0.4063  loss_rpn_cls: 0.1782  loss_rpn_loc: 0.307  time: 1.0051  data_time: 0.6204  lr: 0.00081852  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:55:23 d2.utils.events]: \u001b[0m eta: 0:11:22  iter: 139  total_loss: 1.99  loss_cls: 0.5339  loss_box_reg: 0.5768  loss_mask: 0.3876  loss_rpn_cls: 0.1921  loss_rpn_loc: 0.3268  time: 1.0658  data_time: 1.2047  lr: 0.0010422  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:55:45 d2.utils.events]: \u001b[0m eta: 0:11:14  iter: 159  total_loss: 1.863  loss_cls: 0.4223  loss_box_reg: 0.6038  loss_mask: 0.3677  loss_rpn_cls: 0.1837  loss_rpn_loc: 0.3028  time: 1.0694  data_time: 0.8920  lr: 0.0012814  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:56:07 d2.utils.events]: \u001b[0m eta: 0:11:17  iter: 179  total_loss: 2.002  loss_cls: 0.5507  loss_box_reg: 0.613  loss_mask: 0.3653  loss_rpn_cls: 0.2217  loss_rpn_loc: 0.32  time: 1.0739  data_time: 0.9077  lr: 0.0015288  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:56:36 d2.utils.events]: \u001b[0m eta: 0:11:40  iter: 199  total_loss: 2.103  loss_cls: 0.5392  loss_box_reg: 0.5846  loss_mask: 0.3741  loss_rpn_cls: 0.2319  loss_rpn_loc: 0.3383  time: 1.1090  data_time: 1.2085  lr: 0.0017773  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:56:57 d2.utils.events]: \u001b[0m eta: 0:11:27  iter: 219  total_loss: 1.956  loss_cls: 0.4657  loss_box_reg: 0.586  loss_mask: 0.3734  loss_rpn_cls: 0.1976  loss_rpn_loc: 0.3081  time: 1.1067  data_time: 0.8851  lr: 0.0020192  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:57:21 d2.utils.events]: \u001b[0m eta: 0:11:05  iter: 239  total_loss: 1.842  loss_cls: 0.425  loss_box_reg: 0.575  loss_mask: 0.3413  loss_rpn_cls: 0.1668  loss_rpn_loc: 0.3212  time: 1.1128  data_time: 0.9876  lr: 0.0022474  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:57:47 d2.utils.events]: \u001b[0m eta: 0:10:59  iter: 259  total_loss: 1.848  loss_cls: 0.4331  loss_box_reg: 0.5735  loss_mask: 0.3806  loss_rpn_cls: 0.1821  loss_rpn_loc: 0.2987  time: 1.1259  data_time: 1.0807  lr: 0.002455  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:58:08 d2.utils.events]: \u001b[0m eta: 0:11:01  iter: 279  total_loss: 1.892  loss_cls: 0.4201  loss_box_reg: 0.5987  loss_mask: 0.3567  loss_rpn_cls: 0.205  loss_rpn_loc: 0.3153  time: 1.1215  data_time: 0.8725  lr: 0.0026359  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:58:33 d2.utils.events]: \u001b[0m eta: 0:11:04  iter: 299  total_loss: 1.975  loss_cls: 0.4327  loss_box_reg: 0.5983  loss_mask: 0.3658  loss_rpn_cls: 0.2075  loss_rpn_loc: 0.3397  time: 1.1314  data_time: 1.0715  lr: 0.0027847  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:59:00 d2.utils.events]: \u001b[0m eta: 0:11:00  iter: 319  total_loss: 1.765  loss_cls: 0.3563  loss_box_reg: 0.5646  loss_mask: 0.3608  loss_rpn_cls: 0.1778  loss_rpn_loc: 0.3028  time: 1.1442  data_time: 1.1301  lr: 0.0028968  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:59:19 d2.utils.events]: \u001b[0m eta: 0:10:46  iter: 339  total_loss: 1.96  loss_cls: 0.4518  loss_box_reg: 0.6071  loss_mask: 0.3688  loss_rpn_cls: 0.1603  loss_rpn_loc: 0.326  time: 1.1335  data_time: 0.7772  lr: 0.002969  max_mem: 4256M\n",
      "\u001b[32m[01/06 15:59:37 d2.utils.events]: \u001b[0m eta: 0:09:48  iter: 359  total_loss: 1.887  loss_cls: 0.4257  loss_box_reg: 0.6218  loss_mask: 0.3678  loss_rpn_cls: 0.1719  loss_rpn_loc: 0.2812  time: 1.1208  data_time: 0.7240  lr: 0.0029991  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:00:02 d2.utils.events]: \u001b[0m eta: 0:10:06  iter: 379  total_loss: 1.787  loss_cls: 0.3681  loss_box_reg: 0.5601  loss_mask: 0.3597  loss_rpn_cls: 0.1893  loss_rpn_loc: 0.3009  time: 1.1256  data_time: 1.0172  lr: 0.0029974  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:00:19 d2.utils.events]: \u001b[0m eta: 0:09:20  iter: 399  total_loss: 1.73  loss_cls: 0.3728  loss_box_reg: 0.5806  loss_mask: 0.3433  loss_rpn_cls: 0.1401  loss_rpn_loc: 0.2655  time: 1.1131  data_time: 0.6951  lr: 0.0029866  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:00:38 d2.utils.events]: \u001b[0m eta: 0:09:08  iter: 419  total_loss: 1.806  loss_cls: 0.3703  loss_box_reg: 0.6157  loss_mask: 0.349  loss_rpn_cls: 0.1526  loss_rpn_loc: 0.2916  time: 1.1044  data_time: 0.7478  lr: 0.0029678  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:01:04 d2.utils.events]: \u001b[0m eta: 0:09:11  iter: 439  total_loss: 1.862  loss_cls: 0.4142  loss_box_reg: 0.6084  loss_mask: 0.3562  loss_rpn_cls: 0.1759  loss_rpn_loc: 0.3089  time: 1.1138  data_time: 1.1046  lr: 0.0029408  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:01:26 d2.utils.events]: \u001b[0m eta: 0:09:04  iter: 459  total_loss: 1.867  loss_cls: 0.3822  loss_box_reg: 0.5987  loss_mask: 0.3378  loss_rpn_cls: 0.1859  loss_rpn_loc: 0.3175  time: 1.1141  data_time: 0.9262  lr: 0.0029059  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:01:51 d2.utils.events]: \u001b[0m eta: 0:08:50  iter: 479  total_loss: 1.666  loss_cls: 0.3246  loss_box_reg: 0.5309  loss_mask: 0.3383  loss_rpn_cls: 0.1646  loss_rpn_loc: 0.3095  time: 1.1199  data_time: 1.0394  lr: 0.0028633  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:02:12 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from SartoriusCellSeg/annotations_val.json\n",
      "\u001b[32m[01/06 16:02:13 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(0, 0), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/06 16:02:13 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/06 16:02:13 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/06 16:02:13 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from SartoriusCellSeg/annotations_val.json\n",
      "\u001b[32m[01/06 16:02:13 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/06 16:02:14 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0092 s/iter. Inference: 0.0573 s/iter. Eval: 0.0165 s/iter. Total: 0.0831 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/06 16:02:19 d2.evaluation.evaluator]: \u001b[0mInference done 63/121. Dataloading: 0.0118 s/iter. Inference: 0.0602 s/iter. Eval: 0.0234 s/iter. Total: 0.0955 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/06 16:02:24 d2.evaluation.evaluator]: \u001b[0mInference done 115/121. Dataloading: 0.0122 s/iter. Inference: 0.0604 s/iter. Eval: 0.0240 s/iter. Total: 0.0965 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/06 16:02:25 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.162323 (0.096227 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/06 16:02:25 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:06 (0.060264 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/06 16:02:25 d2.engine.defaults]: \u001b[0mEvaluation results for CellSeg_val in csv format:\n",
      "\u001b[32m[01/06 16:02:25 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.18933584323727637\n",
      "\u001b[32m[01/06 16:02:25 d2.engine.hooks]: \u001b[0mSaved first model at 0.18934 @ 499 steps\n",
      "\u001b[32m[01/06 16:02:25 d2.utils.events]: \u001b[0m eta: 0:08:18  iter: 499  total_loss: 1.727  loss_cls: 0.3402  loss_box_reg: 0.5452  loss_mask: 0.3404  loss_rpn_cls: 0.1545  loss_rpn_loc: 0.2636  time: 1.1154  data_time: 0.8209  lr: 0.0028132  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:02:53 d2.utils.events]: \u001b[0m eta: 0:08:21  iter: 519  total_loss: 1.734  loss_cls: 0.3548  loss_box_reg: 0.5596  loss_mask: 0.3578  loss_rpn_cls: 0.1629  loss_rpn_loc: 0.3035  time: 1.1267  data_time: 1.1910  lr: 0.0027559  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:03:19 d2.utils.events]: \u001b[0m eta: 0:07:59  iter: 539  total_loss: 1.717  loss_cls: 0.3619  loss_box_reg: 0.573  loss_mask: 0.351  loss_rpn_cls: 0.1578  loss_rpn_loc: 0.2972  time: 1.1327  data_time: 1.0839  lr: 0.0026916  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:03:37 d2.utils.events]: \u001b[0m eta: 0:07:31  iter: 559  total_loss: 1.81  loss_cls: 0.4016  loss_box_reg: 0.6021  loss_mask: 0.378  loss_rpn_cls: 0.1476  loss_rpn_loc: 0.3018  time: 1.1241  data_time: 0.7139  lr: 0.0026208  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:04:00 d2.utils.events]: \u001b[0m eta: 0:07:22  iter: 579  total_loss: 1.745  loss_cls: 0.3376  loss_box_reg: 0.5785  loss_mask: 0.3344  loss_rpn_cls: 0.147  loss_rpn_loc: 0.276  time: 1.1247  data_time: 0.9421  lr: 0.0025439  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:04:24 d2.utils.events]: \u001b[0m eta: 0:07:15  iter: 599  total_loss: 1.766  loss_cls: 0.3622  loss_box_reg: 0.5813  loss_mask: 0.3554  loss_rpn_cls: 0.1751  loss_rpn_loc: 0.2778  time: 1.1269  data_time: 0.9941  lr: 0.0024612  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:04:44 d2.utils.events]: \u001b[0m eta: 0:07:00  iter: 619  total_loss: 1.762  loss_cls: 0.3311  loss_box_reg: 0.5728  loss_mask: 0.3566  loss_rpn_cls: 0.14  loss_rpn_loc: 0.314  time: 1.1230  data_time: 0.8281  lr: 0.0023732  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:05:09 d2.utils.events]: \u001b[0m eta: 0:06:53  iter: 639  total_loss: 1.83  loss_cls: 0.4206  loss_box_reg: 0.584  loss_mask: 0.3446  loss_rpn_cls: 0.1729  loss_rpn_loc: 0.2908  time: 1.1275  data_time: 1.0609  lr: 0.0022804  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:05:26 d2.utils.events]: \u001b[0m eta: 0:06:35  iter: 659  total_loss: 1.814  loss_cls: 0.4085  loss_box_reg: 0.5918  loss_mask: 0.3406  loss_rpn_cls: 0.1644  loss_rpn_loc: 0.3093  time: 1.1194  data_time: 0.6871  lr: 0.0021833  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:05:48 d2.utils.events]: \u001b[0m eta: 0:06:17  iter: 679  total_loss: 1.701  loss_cls: 0.3272  loss_box_reg: 0.5621  loss_mask: 0.3358  loss_rpn_cls: 0.1643  loss_rpn_loc: 0.2792  time: 1.1189  data_time: 0.9151  lr: 0.0020825  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:06:09 d2.utils.events]: \u001b[0m eta: 0:06:03  iter: 699  total_loss: 1.882  loss_cls: 0.4039  loss_box_reg: 0.5611  loss_mask: 0.3419  loss_rpn_cls: 0.1682  loss_rpn_loc: 0.3034  time: 1.1159  data_time: 0.8349  lr: 0.0019784  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:06:25 d2.utils.events]: \u001b[0m eta: 0:05:43  iter: 719  total_loss: 1.595  loss_cls: 0.3105  loss_box_reg: 0.5888  loss_mask: 0.3437  loss_rpn_cls: 0.1294  loss_rpn_loc: 0.2604  time: 1.1073  data_time: 0.6226  lr: 0.0018717  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:06:50 d2.utils.events]: \u001b[0m eta: 0:05:38  iter: 739  total_loss: 1.63  loss_cls: 0.3101  loss_box_reg: 0.5462  loss_mask: 0.356  loss_rpn_cls: 0.1612  loss_rpn_loc: 0.2845  time: 1.1121  data_time: 1.0703  lr: 0.001763  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:07:06 d2.utils.events]: \u001b[0m eta: 0:05:12  iter: 759  total_loss: 1.763  loss_cls: 0.3188  loss_box_reg: 0.5244  loss_mask: 0.3387  loss_rpn_cls: 0.1507  loss_rpn_loc: 0.2794  time: 1.1038  data_time: 0.6265  lr: 0.0016529  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:07:25 d2.utils.events]: \u001b[0m eta: 0:04:58  iter: 779  total_loss: 1.67  loss_cls: 0.3628  loss_box_reg: 0.552  loss_mask: 0.3245  loss_rpn_cls: 0.1535  loss_rpn_loc: 0.2879  time: 1.0994  data_time: 0.7473  lr: 0.0015419  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:07:47 d2.utils.events]: \u001b[0m eta: 0:04:43  iter: 799  total_loss: 1.472  loss_cls: 0.2849  loss_box_reg: 0.5159  loss_mask: 0.3019  loss_rpn_cls: 0.1308  loss_rpn_loc: 0.2487  time: 1.0994  data_time: 0.9099  lr: 0.0014306  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:08:11 d2.utils.events]: \u001b[0m eta: 0:04:29  iter: 819  total_loss: 1.709  loss_cls: 0.3454  loss_box_reg: 0.5161  loss_mask: 0.3327  loss_rpn_cls: 0.151  loss_rpn_loc: 0.3003  time: 1.1012  data_time: 0.9764  lr: 0.0013198  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:08:42 d2.utils.events]: \u001b[0m eta: 0:04:15  iter: 839  total_loss: 1.655  loss_cls: 0.3134  loss_box_reg: 0.5308  loss_mask: 0.3455  loss_rpn_cls: 0.142  loss_rpn_loc: 0.2651  time: 1.1120  data_time: 1.3144  lr: 0.0012099  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:09:08 d2.utils.events]: \u001b[0m eta: 0:04:02  iter: 859  total_loss: 1.718  loss_cls: 0.3504  loss_box_reg: 0.5727  loss_mask: 0.3556  loss_rpn_cls: 0.1711  loss_rpn_loc: 0.3338  time: 1.1164  data_time: 1.1006  lr: 0.0011017  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:09:35 d2.utils.events]: \u001b[0m eta: 0:03:48  iter: 879  total_loss: 1.705  loss_cls: 0.3482  loss_box_reg: 0.5394  loss_mask: 0.3426  loss_rpn_cls: 0.1684  loss_rpn_loc: 0.2939  time: 1.1221  data_time: 1.1673  lr: 0.0009956  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:09:54 d2.utils.events]: \u001b[0m eta: 0:03:34  iter: 899  total_loss: 1.537  loss_cls: 0.2918  loss_box_reg: 0.4866  loss_mask: 0.3331  loss_rpn_cls: 0.1385  loss_rpn_loc: 0.2727  time: 1.1182  data_time: 0.7662  lr: 0.00089231  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:10:12 d2.utils.events]: \u001b[0m eta: 0:03:19  iter: 919  total_loss: 1.717  loss_cls: 0.3861  loss_box_reg: 0.5329  loss_mask: 0.3437  loss_rpn_cls: 0.1322  loss_rpn_loc: 0.2659  time: 1.1131  data_time: 0.7065  lr: 0.00079236  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:10:34 d2.utils.events]: \u001b[0m eta: 0:03:04  iter: 939  total_loss: 1.596  loss_cls: 0.3148  loss_box_reg: 0.5325  loss_mask: 0.3564  loss_rpn_cls: 0.1457  loss_rpn_loc: 0.2754  time: 1.1130  data_time: 0.9187  lr: 0.0006963  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:10:53 d2.utils.events]: \u001b[0m eta: 0:02:50  iter: 959  total_loss: 1.729  loss_cls: 0.3625  loss_box_reg: 0.5771  loss_mask: 0.3401  loss_rpn_cls: 0.1443  loss_rpn_loc: 0.3061  time: 1.1101  data_time: 0.7895  lr: 0.00060467  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:11:16 d2.utils.events]: \u001b[0m eta: 0:02:37  iter: 979  total_loss: 1.711  loss_cls: 0.3421  loss_box_reg: 0.5687  loss_mask: 0.3356  loss_rpn_cls: 0.1469  loss_rpn_loc: 0.2808  time: 1.1102  data_time: 0.9120  lr: 0.00051796  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:11:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from SartoriusCellSeg/annotations_val.json\n",
      "\u001b[32m[01/06 16:11:33 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(0, 0), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/06 16:11:33 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/06 16:11:33 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/06 16:11:33 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from SartoriusCellSeg/annotations_val.json\n",
      "\u001b[32m[01/06 16:11:33 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/06 16:11:34 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0092 s/iter. Inference: 0.0581 s/iter. Eval: 0.0191 s/iter. Total: 0.0865 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/06 16:11:39 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0117 s/iter. Inference: 0.0611 s/iter. Eval: 0.0255 s/iter. Total: 0.0983 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/06 16:11:45 d2.evaluation.evaluator]: \u001b[0mInference done 111/121. Dataloading: 0.0122 s/iter. Inference: 0.0616 s/iter. Eval: 0.0267 s/iter. Total: 0.1006 s/iter. ETA=0:00:01\n",
      "\u001b[32m[01/06 16:11:45 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.583880 (0.099861 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/06 16:11:45 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.061374 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/06 16:11:45 d2.engine.defaults]: \u001b[0mEvaluation results for CellSeg_val in csv format:\n",
      "\u001b[32m[01/06 16:11:45 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.21097433602096863\n",
      "\u001b[32m[01/06 16:11:46 d2.engine.hooks]: \u001b[0mSaved best model as latest eval score for MaP IoU is 0.21097, better than last best score 0.18934 @ iteration 499.\n",
      "\u001b[32m[01/06 16:11:46 d2.utils.events]: \u001b[0m eta: 0:02:21  iter: 999  total_loss: 1.53  loss_cls: 0.2553  loss_box_reg: 0.5561  loss_mask: 0.3358  loss_rpn_cls: 0.1102  loss_rpn_loc: 0.2669  time: 1.1043  data_time: 0.6422  lr: 0.00043665  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:12:10 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 1019  total_loss: 1.65  loss_cls: 0.3294  loss_box_reg: 0.5031  loss_mask: 0.3608  loss_rpn_cls: 0.1619  loss_rpn_loc: 0.2937  time: 1.1064  data_time: 1.0185  lr: 0.00036119  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:12:32 d2.utils.events]: \u001b[0m eta: 0:01:55  iter: 1039  total_loss: 1.68  loss_cls: 0.3257  loss_box_reg: 0.5491  loss_mask: 0.3558  loss_rpn_cls: 0.1662  loss_rpn_loc: 0.2831  time: 1.1061  data_time: 0.8946  lr: 0.000292  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:12:55 d2.utils.events]: \u001b[0m eta: 0:01:42  iter: 1059  total_loss: 1.673  loss_cls: 0.3095  loss_box_reg: 0.5558  loss_mask: 0.3603  loss_rpn_cls: 0.1478  loss_rpn_loc: 0.2965  time: 1.1065  data_time: 0.9360  lr: 0.00022945  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:13:15 d2.utils.events]: \u001b[0m eta: 0:01:28  iter: 1079  total_loss: 1.62  loss_cls: 0.3211  loss_box_reg: 0.5314  loss_mask: 0.3478  loss_rpn_cls: 0.1255  loss_rpn_loc: 0.2763  time: 1.1050  data_time: 0.8352  lr: 0.00017389  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:13:37 d2.utils.events]: \u001b[0m eta: 0:01:14  iter: 1099  total_loss: 1.747  loss_cls: 0.3091  loss_box_reg: 0.5469  loss_mask: 0.3522  loss_rpn_cls: 0.1367  loss_rpn_loc: 0.2823  time: 1.1052  data_time: 0.9194  lr: 0.00012563  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:14:06 d2.utils.events]: \u001b[0m eta: 0:01:01  iter: 1119  total_loss: 1.619  loss_cls: 0.3609  loss_box_reg: 0.5221  loss_mask: 0.3271  loss_rpn_cls: 0.1603  loss_rpn_loc: 0.2952  time: 1.1108  data_time: 1.2091  lr: 8.4927e-05  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:14:25 d2.utils.events]: \u001b[0m eta: 0:00:47  iter: 1139  total_loss: 1.622  loss_cls: 0.3071  loss_box_reg: 0.5411  loss_mask: 0.3334  loss_rpn_cls: 0.1312  loss_rpn_loc: 0.2895  time: 1.1085  data_time: 0.8043  lr: 5.2008e-05  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:14:45 d2.utils.events]: \u001b[0m eta: 0:00:33  iter: 1159  total_loss: 1.587  loss_cls: 0.3112  loss_box_reg: 0.5275  loss_mask: 0.3167  loss_rpn_cls: 0.1439  loss_rpn_loc: 0.28  time: 1.1061  data_time: 0.7942  lr: 2.7054e-05  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:15:07 d2.utils.events]: \u001b[0m eta: 0:00:20  iter: 1179  total_loss: 1.645  loss_cls: 0.332  loss_box_reg: 0.5735  loss_mask: 0.3507  loss_rpn_cls: 0.1408  loss_rpn_loc: 0.263  time: 1.1062  data_time: 0.9154  lr: 1.0204e-05  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:15:32 d2.utils.events]: \u001b[0m eta: 0:00:06  iter: 1199  total_loss: 1.536  loss_cls: 0.2826  loss_box_reg: 0.5152  loss_mask: 0.3259  loss_rpn_cls: 0.1159  loss_rpn_loc: 0.2613  time: 1.1084  data_time: 1.0231  lr: 1.5482e-06  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:15:43 d2.utils.events]: \u001b[0m eta: 0:00:00  iter: 1209  total_loss: 1.575  loss_cls: 0.3096  loss_box_reg: 0.518  loss_mask: 0.35  loss_rpn_cls: 0.1292  loss_rpn_loc: 0.2818  time: 1.1079  data_time: 1.0548  lr: 3.1032e-07  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:15:43 d2.engine.hooks]: \u001b[0mOverall training speed: 1208 iterations in 0:22:18 (1.1079 s / it)\n",
      "\u001b[32m[01/06 16:15:43 d2.engine.hooks]: \u001b[0mTotal training time: 0:22:46 (0:00:28 on hooks)\n",
      "\u001b[32m[01/06 16:15:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from SartoriusCellSeg/annotations_val.json\n",
      "\u001b[32m[01/06 16:15:43 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(0, 0), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/06 16:15:43 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/06 16:15:43 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/06 16:15:43 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from SartoriusCellSeg/annotations_val.json\n",
      "\u001b[32m[01/06 16:15:44 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/06 16:15:45 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0096 s/iter. Inference: 0.0573 s/iter. Eval: 0.0166 s/iter. Total: 0.0835 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/06 16:15:50 d2.evaluation.evaluator]: \u001b[0mInference done 61/121. Dataloading: 0.0138 s/iter. Inference: 0.0606 s/iter. Eval: 0.0243 s/iter. Total: 0.0987 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/06 16:15:55 d2.evaluation.evaluator]: \u001b[0mInference done 111/121. Dataloading: 0.0133 s/iter. Inference: 0.0610 s/iter. Eval: 0.0255 s/iter. Total: 0.0999 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/06 16:15:56 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.498324 (0.099123 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/06 16:15:56 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.060855 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/06 16:15:56 d2.engine.defaults]: \u001b[0mEvaluation results for CellSeg_val in csv format:\n",
      "\u001b[32m[01/06 16:15:56 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.21256034769420562\n",
      "\u001b[32m[01/06 16:15:56 d2.engine.hooks]: \u001b[0mSaved best model as latest eval score for MaP IoU is 0.21256, better than last best score 0.21097 @ iteration 999.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 260... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>MaP IoU</td><td>▁██</td></tr><tr><td>data_time</td><td>▄▂▄▂▆▃▆▃▅▄█▃█▃▅▃▂▃▃▅▃▂▂▂▅▃▃█▆▂▂▃▁▆▅▃▇▃▃▆</td></tr><tr><td>eta_seconds</td><td>█▆▆▅▅▅▅▅▅▅▅▅▅▄▄▄▄▄▄▄▄▃▃▃▃▃▃▃▂▂▂▂▂▂▂▂▁▁▁▁</td></tr><tr><td>fast_rcnn/cls_accuracy</td><td>▁▁▁▃▃▅▃▄▄▅▅▄▆▅▅▆▅▆▅▆▆▅▇▆▆▆▆▇▆█▇▆█▇▇▆▆▇▆▆</td></tr><tr><td>fast_rcnn/false_negative</td><td>███▆▅▄▆▄▄▄▃▄▃▄▄▂▃▃▃▃▃▃▁▃▂▃▃▃▃▂▃▃▂▃▂▂▃▃▃▂</td></tr><tr><td>fast_rcnn/fg_cls_accuracy</td><td>▁▁▁▃▃▅▃▅▅▅▆▅▆▅▅▇▆▆▆▆▆▆█▆▇▆▆▆▆▇▆▆▇▆▇▇▆▆▆▇</td></tr><tr><td>global_step</td><td>▁▁▁▁▂▂▂▂▂▃▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▆▇▇▇▇▇████</td></tr><tr><td>loss_box_reg</td><td>▁▄▇█▆▇▆▆▆▇▅▇▅▇▇▄▅▆▇▆▆▆▅▆▅▅▄▄▅▃▄▆▅▃▅▄▄▅▆▄</td></tr><tr><td>loss_cls</td><td>█▅▄▄▃▂▃▃▃▂▂▃▂▂▂▂▂▂▂▂▂▂▂▁▁▂▂▂▂▁▂▂▁▂▁▂▂▁▂▁</td></tr><tr><td>loss_mask</td><td>█▇▄▃▂▂▂▂▂▂▂▂▂▁▂▁▁▂▂▂▂▁▁▁▂▁▁▁▁▁▂▁▁▂▂▁▁▁▂▁</td></tr><tr><td>loss_rpn_cls</td><td>█▆▃▂▂▂▃▂▂▃▂▂▂▂▂▂▂▂▂▂▁▂▂▁▂▂▂▂▂▁▂▂▁▂▂▁▂▁▂▁</td></tr><tr><td>loss_rpn_loc</td><td>█▇▅▅▄▃▅▃▃▄▃▄▃▃▃▄▁▃▃▂▄▃▂▁▂▂▃▁▃▂▂▃▁▃▃▂▃▂▁▂</td></tr><tr><td>lr</td><td>▁▁▂▂▃▄▅▆▇▇███████▇▇▇▇▆▆▅▅▅▄▄▃▃▃▂▂▂▂▁▁▁▁▁</td></tr><tr><td>mask_rcnn/accuracy</td><td>▁▃▅▆▇▇▇▇▇█▇▇▇█▇██▇▇▇▇▇██▇███▇█▇██▇▇▇██▇█</td></tr><tr><td>mask_rcnn/false_negative</td><td>▁▇▅█▇▇█▇▇█▆▇▆▆▆▆▆▇▇▇▆▇▆▆▇▇▇▆▆▆▆▇▆▇▇▆▆▆▇▆</td></tr><tr><td>mask_rcnn/false_positive</td><td>█▃▂▂▂▂▁▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▂▁▁▁▁▂▁▂▁▂▁▁▂▁▁▁▁</td></tr><tr><td>momentum</td><td>██▇▇▆▅▄▃▂▂▁▁▁▁▁▁▁▂▂▂▂▃▃▄▄▄▅▅▆▆▆▇▇▇▇█████</td></tr><tr><td>roi_head/num_bg_samples</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>roi_head/num_fg_samples</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>rpn/num_neg_anchors</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>rpn/num_pos_anchors</td><td>▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>time</td><td>▅▂▄▂▇▃▆▃▅▄█▄█▃▆▄▂▃▃▅▃▂▂▃▅▃▃█▆▂▂▃▁▆▅▃▇▃▃▆</td></tr><tr><td>total_loss</td><td>█▆▅▄▃▃▄▃▂▃▂▃▂▂▃▂▂▂▂▂▂▂▂▁▁▂▂▂▂▁▁▂▁▂▂▁▁▁▂▁</td></tr></table><br/></div><div class=\"wandb-col\">\n",
       "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>MaP IoU</td><td>0.21256</td></tr><tr><td>data_time</td><td>0.85842</td></tr><tr><td>eta_seconds</td><td>0.0</td></tr><tr><td>fast_rcnn/cls_accuracy</td><td>0.85547</td></tr><tr><td>fast_rcnn/false_negative</td><td>0.35938</td></tr><tr><td>fast_rcnn/fg_cls_accuracy</td><td>0.64062</td></tr><tr><td>global_step</td><td>1210</td></tr><tr><td>loss_box_reg</td><td>0.51803</td></tr><tr><td>loss_cls</td><td>0.30959</td></tr><tr><td>loss_mask</td><td>0.35005</td></tr><tr><td>loss_rpn_cls</td><td>0.12919</td></tr><tr><td>loss_rpn_loc</td><td>0.28184</td></tr><tr><td>lr</td><td>0.0</td></tr><tr><td>mask_rcnn/accuracy</td><td>0.84068</td></tr><tr><td>mask_rcnn/false_negative</td><td>0.11772</td></tr><tr><td>mask_rcnn/false_positive</td><td>0.20934</td></tr><tr><td>momentum</td><td>0.95</td></tr><tr><td>roi_head/num_bg_samples</td><td>48.0</td></tr><tr><td>roi_head/num_fg_samples</td><td>16.0</td></tr><tr><td>rpn/num_neg_anchors</td><td>128.0</td></tr><tr><td>rpn/num_pos_anchors</td><td>128.0</td></tr><tr><td>time</td><td>1.04629</td></tr><tr><td>total_loss</td><td>1.57472</td></tr></table>\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 1 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">R50-oneCycle-sweeps</strong>: <a href=\"https://wandb.ai/ben-karr/CellSeg/runs/047ylhyp\" target=\"_blank\">https://wandb.ai/ben-karr/CellSeg/runs/047ylhyp</a><br/>\n",
       "Find logs at: <code>./wandb/run-20220106_155248-047ylhyp/logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: z2b58v68 with config:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatch_size: 4\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tbrightness: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcontrast: 0.3\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tcrop_size: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 5\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \thor_vert_flips: [True, True]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearning_rate: 0.003\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tmixed_precision: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tnesterov: True\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \troi_bs: 64\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \trotation: 15\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tsaturation: False\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tshortest_edge_size: [440, 480, 520, 560, 580, 620]\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \tweight_decay: 0.0007991565694529167\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg project when running a sweep\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/ben-karr/CellSeg/runs/z2b58v68\" target=\"_blank\">R50-oneCycle-sweeps</a></strong> to <a href=\"https://wandb.ai/ben-karr/CellSeg\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "Sweep page: <a href=\"https://wandb.ai/ben-karr/CellSeg/sweeps/gzjsnknx\" target=\"_blank\">https://wandb.ai/ben-karr/CellSeg/sweeps/gzjsnknx</a><br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/06 16:16:14 d2.data.datasets.coco]: \u001b[0mLoading SartoriusCellSeg/annotations_train.json takes 1.19 seconds.\n",
      "\u001b[32m[01/06 16:16:14 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from SartoriusCellSeg/annotations_train.json\n",
      "Total iterations: 605\n",
      "\u001b[32m[01/06 16:16:16 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in training: [RandomRotation(angle=[-15, 15], expand=False), ResizeShortestEdge(short_edge_length=[440, 480, 520, 560, 580, 620], max_size=1333, sample_style='choice'), RandomFlip(prob=0.5), RandomFlip(prob=0.5, horizontal=False, vertical=True), RandomContrast(intensity_min=0.7, intensity_max=1.3), RandomBrightness(intensity_min=0.7, intensity_max=1.3)]\n",
      "\u001b[32m[01/06 16:16:17 d2.data.datasets.coco]: \u001b[0mLoading SartoriusCellSeg/annotations_train.json takes 1.02 seconds.\n",
      "\u001b[32m[01/06 16:16:17 d2.data.datasets.coco]: \u001b[0mLoaded 485 images in COCO format from SartoriusCellSeg/annotations_train.json\n",
      "\u001b[32m[01/06 16:16:18 d2.data.build]: \u001b[0mRemoved 0 images with no usable annotations. 485 images left.\n",
      "\u001b[32m[01/06 16:16:18 d2.data.build]: \u001b[0mUsing training sampler TrainingSampler\n",
      "\u001b[32m[01/06 16:16:18 d2.data.common]: \u001b[0mSerializing 485 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/06 16:16:18 d2.data.common]: \u001b[0mSerialized dataset takes 6.71 MiB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.weight' to the model due to incompatible shapes: (81, 1024) in the checkpoint but (4, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.cls_score.bias' to the model due to incompatible shapes: (81,) in the checkpoint but (4,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.weight' to the model due to incompatible shapes: (320, 1024) in the checkpoint but (12, 1024) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.box_predictor.bbox_pred.bias' to the model due to incompatible shapes: (320,) in the checkpoint but (12,) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.weight' to the model due to incompatible shapes: (80, 256, 1, 1) in the checkpoint but (3, 256, 1, 1) in the model! You might want to double check if this is expected.\n",
      "Skip loading parameter 'roi_heads.mask_head.predictor.bias' to the model due to incompatible shapes: (80,) in the checkpoint but (3,) in the model! You might want to double check if this is expected.\n",
      "Some model parameters or buffers are not found in the checkpoint:\n",
      "\u001b[34mroi_heads.box_predictor.bbox_pred.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.box_predictor.cls_score.{bias, weight}\u001b[0m\n",
      "\u001b[34mroi_heads.mask_head.predictor.{bias, weight}\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/06 16:16:18 d2.engine.train_loop]: \u001b[0mStarting training from iteration 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/studio-lab-user/SartoriusCellSegmentation/onecycle.py:130: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m[01/06 16:17:06 d2.utils.events]: \u001b[0m eta: 0:22:21  iter: 19  total_loss: 3.005  loss_cls: 1.004  loss_box_reg: 0.3534  loss_mask: 0.6862  loss_rpn_cls: 0.5073  loss_rpn_loc: 0.447  time: 2.5792  data_time: 2.0153  lr: 0.00019717  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:17:46 d2.utils.events]: \u001b[0m eta: 0:20:14  iter: 39  total_loss: 2.657  loss_cls: 0.7474  loss_box_reg: 0.5481  loss_mask: 0.6322  loss_rpn_cls: 0.3327  loss_rpn_loc: 0.3677  time: 2.2741  data_time: 1.6167  lr: 0.00043583  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:18:24 d2.utils.events]: \u001b[0m eta: 0:18:29  iter: 59  total_loss: 2.457  loss_cls: 0.6837  loss_box_reg: 0.6425  loss_mask: 0.488  loss_rpn_cls: 0.2514  loss_rpn_loc: 0.3556  time: 2.1377  data_time: 1.5097  lr: 0.00080787  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:19:14 d2.utils.events]: \u001b[0m eta: 0:18:21  iter: 79  total_loss: 2.217  loss_cls: 0.5923  loss_box_reg: 0.6108  loss_mask: 0.4018  loss_rpn_cls: 0.2502  loss_rpn_loc: 0.3463  time: 2.2305  data_time: 2.0942  lr: 0.0012691  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:19:55 d2.utils.events]: \u001b[0m eta: 0:17:39  iter: 99  total_loss: 2.012  loss_cls: 0.5152  loss_box_reg: 0.5989  loss_mask: 0.3775  loss_rpn_cls: 0.2048  loss_rpn_loc: 0.3342  time: 2.1946  data_time: 1.6780  lr: 0.0017649  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:20:39 d2.utils.events]: \u001b[0m eta: 0:16:57  iter: 119  total_loss: 1.994  loss_cls: 0.4915  loss_box_reg: 0.5836  loss_mask: 0.373  loss_rpn_cls: 0.1853  loss_rpn_loc: 0.3426  time: 2.1974  data_time: 1.8211  lr: 0.0022364  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:21:13 d2.utils.events]: \u001b[0m eta: 0:15:34  iter: 139  total_loss: 1.961  loss_cls: 0.4618  loss_box_reg: 0.6061  loss_mask: 0.3721  loss_rpn_cls: 0.1743  loss_rpn_loc: 0.3121  time: 2.1266  data_time: 1.3507  lr: 0.0026276  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:21:59 d2.utils.events]: \u001b[0m eta: 0:14:52  iter: 159  total_loss: 1.882  loss_cls: 0.4045  loss_box_reg: 0.5613  loss_mask: 0.3655  loss_rpn_cls: 0.1747  loss_rpn_loc: 0.3256  time: 2.1444  data_time: 1.8812  lr: 0.0028922  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:22:47 d2.utils.events]: \u001b[0m eta: 0:14:13  iter: 179  total_loss: 1.825  loss_cls: 0.4378  loss_box_reg: 0.6145  loss_mask: 0.353  loss_rpn_cls: 0.1567  loss_rpn_loc: 0.3086  time: 2.1752  data_time: 2.0115  lr: 0.0029987  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:23:31 d2.utils.events]: \u001b[0m eta: 0:13:32  iter: 199  total_loss: 1.842  loss_cls: 0.3696  loss_box_reg: 0.569  loss_mask: 0.3699  loss_rpn_cls: 0.1636  loss_rpn_loc: 0.3044  time: 2.1789  data_time: 1.8301  lr: 0.0029874  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:24:17 d2.utils.events]: \u001b[0m eta: 0:12:51  iter: 219  total_loss: 1.777  loss_cls: 0.3816  loss_box_reg: 0.6094  loss_mask: 0.3579  loss_rpn_cls: 0.1757  loss_rpn_loc: 0.3036  time: 2.1868  data_time: 1.8844  lr: 0.0029423  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:25:01 d2.utils.events]: \u001b[0m eta: 0:12:12  iter: 239  total_loss: 1.82  loss_cls: 0.4045  loss_box_reg: 0.5711  loss_mask: 0.3689  loss_rpn_cls: 0.1722  loss_rpn_loc: 0.3184  time: 2.1910  data_time: 1.8431  lr: 0.0028656  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:25:52 d2.utils.events]: \u001b[0m eta: 0:11:40  iter: 259  total_loss: 1.793  loss_cls: 0.4196  loss_box_reg: 0.5536  loss_mask: 0.3472  loss_rpn_cls: 0.1708  loss_rpn_loc: 0.2968  time: 2.2162  data_time: 2.1084  lr: 0.0027589  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:26:40 d2.utils.events]: \u001b[0m eta: 0:11:01  iter: 279  total_loss: 1.733  loss_cls: 0.3848  loss_box_reg: 0.5436  loss_mask: 0.3493  loss_rpn_cls: 0.1531  loss_rpn_loc: 0.2993  time: 2.2312  data_time: 2.0260  lr: 0.0026245  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:27:22 d2.utils.events]: \u001b[0m eta: 0:10:14  iter: 299  total_loss: 1.767  loss_cls: 0.3716  loss_box_reg: 0.597  loss_mask: 0.3548  loss_rpn_cls: 0.1461  loss_rpn_loc: 0.2873  time: 2.2224  data_time: 1.7244  lr: 0.0024654  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:28:06 d2.utils.events]: \u001b[0m eta: 0:09:34  iter: 319  total_loss: 1.807  loss_cls: 0.3747  loss_box_reg: 0.6081  loss_mask: 0.3661  loss_rpn_cls: 0.1655  loss_rpn_loc: 0.2977  time: 2.2216  data_time: 1.8118  lr: 0.0022851  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:28:53 d2.utils.events]: \u001b[0m eta: 0:08:54  iter: 339  total_loss: 1.769  loss_cls: 0.3558  loss_box_reg: 0.5538  loss_mask: 0.3549  loss_rpn_cls: 0.1443  loss_rpn_loc: 0.2575  time: 2.2271  data_time: 1.9232  lr: 0.0020876  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:29:35 d2.utils.events]: \u001b[0m eta: 0:08:12  iter: 359  total_loss: 1.655  loss_cls: 0.3283  loss_box_reg: 0.5477  loss_mask: 0.3489  loss_rpn_cls: 0.1374  loss_rpn_loc: 0.298  time: 2.2200  data_time: 1.7133  lr: 0.0018771  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:30:20 d2.utils.events]: \u001b[0m eta: 0:07:32  iter: 379  total_loss: 1.696  loss_cls: 0.341  loss_box_reg: 0.5906  loss_mask: 0.3567  loss_rpn_cls: 0.1369  loss_rpn_loc: 0.2824  time: 2.2219  data_time: 1.8668  lr: 0.0016584  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:31:06 d2.utils.events]: \u001b[0m eta: 0:06:51  iter: 399  total_loss: 1.737  loss_cls: 0.3461  loss_box_reg: 0.5509  loss_mask: 0.3512  loss_rpn_cls: 0.1622  loss_rpn_loc: 0.2816  time: 2.2268  data_time: 1.9280  lr: 0.0014362  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:31:42 d2.utils.events]: \u001b[0m eta: 0:06:09  iter: 419  total_loss: 1.709  loss_cls: 0.3667  loss_box_reg: 0.5861  loss_mask: 0.3281  loss_rpn_cls: 0.1428  loss_rpn_loc: 0.2825  time: 2.2050  data_time: 1.4178  lr: 0.0012154  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:32:27 d2.utils.events]: \u001b[0m eta: 0:05:29  iter: 439  total_loss: 1.763  loss_cls: 0.3506  loss_box_reg: 0.5699  loss_mask: 0.3535  loss_rpn_cls: 0.1628  loss_rpn_loc: 0.3118  time: 2.2085  data_time: 1.8833  lr: 0.0010008  max_mem: 4256M\n",
      "\u001b[32m[01/06 16:33:17 d2.utils.events]: \u001b[0m eta: 0:04:49  iter: 459  total_loss: 1.734  loss_cls: 0.3879  loss_box_reg: 0.5584  loss_mask: 0.3548  loss_rpn_cls: 0.1494  loss_rpn_loc: 0.3043  time: 2.2201  data_time: 2.0648  lr: 0.00079727  max_mem: 4443M\n",
      "\u001b[32m[01/06 16:34:00 d2.utils.events]: \u001b[0m eta: 0:04:09  iter: 479  total_loss: 1.689  loss_cls: 0.3175  loss_box_reg: 0.5611  loss_mask: 0.3682  loss_rpn_cls: 0.1567  loss_rpn_loc: 0.2941  time: 2.2185  data_time: 1.7964  lr: 0.00060914  max_mem: 4443M\n",
      "\u001b[32m[01/06 16:34:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from SartoriusCellSeg/annotations_val.json\n",
      "\u001b[32m[01/06 16:34:39 d2.data.dataset_mapper]: \u001b[0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(0, 0), max_size=1333, sample_style='choice')]\n",
      "\u001b[32m[01/06 16:34:39 d2.data.common]: \u001b[0mSerializing 121 elements to byte tensors and concatenating them all ...\n",
      "\u001b[32m[01/06 16:34:39 d2.data.common]: \u001b[0mSerialized dataset takes 1.72 MiB\n",
      "\u001b[32m[01/06 16:34:39 d2.data.datasets.coco]: \u001b[0mLoaded 121 images in COCO format from SartoriusCellSeg/annotations_val.json\n",
      "\u001b[32m[01/06 16:34:40 d2.evaluation.evaluator]: \u001b[0mStart inference on 121 batches\n",
      "\u001b[32m[01/06 16:34:41 d2.evaluation.evaluator]: \u001b[0mInference done 11/121. Dataloading: 0.0092 s/iter. Inference: 0.0581 s/iter. Eval: 0.0196 s/iter. Total: 0.0868 s/iter. ETA=0:00:09\n",
      "\u001b[32m[01/06 16:34:46 d2.evaluation.evaluator]: \u001b[0mInference done 62/121. Dataloading: 0.0117 s/iter. Inference: 0.0606 s/iter. Eval: 0.0247 s/iter. Total: 0.0970 s/iter. ETA=0:00:05\n",
      "\u001b[32m[01/06 16:34:51 d2.evaluation.evaluator]: \u001b[0mInference done 112/121. Dataloading: 0.0122 s/iter. Inference: 0.0609 s/iter. Eval: 0.0255 s/iter. Total: 0.0987 s/iter. ETA=0:00:00\n",
      "\u001b[32m[01/06 16:34:52 d2.evaluation.evaluator]: \u001b[0mTotal inference time: 0:00:11.382499 (0.098125 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/06 16:34:52 d2.evaluation.evaluator]: \u001b[0mTotal inference pure compute time: 0:00:07 (0.060764 s / iter per device, on 1 devices)\n",
      "\u001b[32m[01/06 16:34:52 d2.engine.defaults]: \u001b[0mEvaluation results for CellSeg_val in csv format:\n",
      "\u001b[32m[01/06 16:34:52 d2.evaluation.testing]: \u001b[0mcopypaste: MaP IoU=0.2031221897214042\n",
      "\u001b[32m[01/06 16:34:52 d2.engine.hooks]: \u001b[0mSaved first model at 0.20312 @ 499 steps\n",
      "\u001b[32m[01/06 16:34:52 d2.utils.events]: \u001b[0m eta: 0:03:27  iter: 499  total_loss: 1.643  loss_cls: 0.3246  loss_box_reg: 0.557  loss_mask: 0.3508  loss_rpn_cls: 0.1553  loss_rpn_loc: 0.2748  time: 2.2054  data_time: 1.5333  lr: 0.00044058  max_mem: 4443M\n",
      "\u001b[32m[01/06 16:35:35 d2.utils.events]: \u001b[0m eta: 0:02:48  iter: 519  total_loss: 1.714  loss_cls: 0.3583  loss_box_reg: 0.5541  loss_mask: 0.3467  loss_rpn_cls: 0.1439  loss_rpn_loc: 0.302  time: 2.2026  data_time: 1.7395  lr: 0.0002953  max_mem: 4443M\n",
      "\u001b[32m[01/06 16:36:22 d2.utils.events]: \u001b[0m eta: 0:02:08  iter: 539  total_loss: 1.701  loss_cls: 0.3354  loss_box_reg: 0.5551  loss_mask: 0.3501  loss_rpn_cls: 0.1628  loss_rpn_loc: 0.2883  time: 2.2087  data_time: 1.9940  lr: 0.0001765  max_mem: 4443M\n",
      "\u001b[32m[01/06 16:37:08 d2.utils.events]: \u001b[0m eta: 0:01:29  iter: 559  total_loss: 1.675  loss_cls: 0.3121  loss_box_reg: 0.5465  loss_mask: 0.3525  loss_rpn_cls: 0.136  loss_rpn_loc: 0.2758  time: 2.2129  data_time: 1.9282  lr: 8.6779e-05  max_mem: 4443M\n",
      "\u001b[32m[01/06 16:37:51 d2.utils.events]: \u001b[0m eta: 0:00:49  iter: 579  total_loss: 1.673  loss_cls: 0.3252  loss_box_reg: 0.562  loss_mask: 0.3524  loss_rpn_cls: 0.1461  loss_rpn_loc: 0.2708  time: 2.2098  data_time: 1.7298  lr: 2.8111e-05  max_mem: 4443M\n",
      "\u001b[32m[01/06 16:38:34 d2.utils.events]: \u001b[0m eta: 0:00:09  iter: 599  total_loss: 1.581  loss_cls: 0.2992  loss_box_reg: 0.5364  loss_mask: 0.3534  loss_rpn_cls: 0.1407  loss_rpn_loc: 0.2772  time: 2.2074  data_time: 1.7523  lr: 1.7854e-06  max_mem: 4443M\n"
     ]
    }
   ],
   "source": [
    "#sweep_id = wandb.sweep(run_config['sweep_config'], project = run_config['project']['name'])\n",
    "sweep_id = 'ben-karr/CellSeg/gzjsnknx'\n",
    "wandb.agent(sweep_id, train, count = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57db4d4-6228-435a-aa65-cdcdda2d60ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test:Python",
   "language": "python",
   "name": "conda-env-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
